---
title: 为什么最终选择了游标分页？
published: 2025-06-10
description: 除了游标分页和索引优化，还有没有考虑过其他方案（如将历史日志归档到更合适的存储如 Elasticsearch/HBase、使用更强大的分页组件）？为什么最终选择了游标分页？
tags: [Markdown, Blogging]
category: Java mianshi
licenseName: "Unlicensed"
author: Ankou
sourceLink: ''
draft: false
---
**除了游标分页和索引优化，还有没有考虑过其他方案（如将历史日志归档到更合适的存储如 Elasticsearch/HBase、使用更强大的分页组件）？为什么最终选择了游标分页？**

在优化智慧园区设备日志查询时，除了游标分页和索引优化，我确实深入评估过多种替代方案。以下是完整的技术选型分析和最终选择游标分页的理由：

一、备选方案深度评估

1. **历史日志归档到专用存储**

**方案A: Elasticsearch**

- 实现路径：

  ![](/q_img/Elasticsearch​.png)

- 优势：

  - 分布式架构支持PB级数据
  - 倒排索引适合复杂条件查询（如多字段过滤）
  - 支持聚合分析（如操作类型统计）

- 致命缺陷：

  - **实时性不足**：Logstash分钟级同步延迟，无法满足设备故障需实时查日志的需求
  - **资源消耗**：30万日志需额外2节点ES集群（成本增加40%）
  - **数据一致性**：双写方案复杂，单写ES又无法保证事务

**方案B: HBase**

- 实现路径：

  ```java
  // 使用HBase的Scan+Filter分页
  Scan scan = new Scan();
  scan.setFilter(new PageFilter(10));
  scan.setStartRow(lastRowKey);  // 基于RowKey连续分页
  ```

- 优势：

  - LSM树结构适合写密集型场景
  - 原生支持海量数据扫描

- 致命缺陷：

  - **查询功能弱**：缺乏原生SQL支持，多条件查询需开发自定义过滤器
  - **运维复杂度**：需引入HBase集群和Zookeeper（原技术栈无Hadoop生态）
  - **性能陷阱**：RegionServer热点问题需精心设计RowKey

**结论**：因实时性和架构复杂度问题排除

2. **分页组件优化**

**方案A: MyBatis分页插件**

```xml
<dependency>
    <groupId>com.github.pagehelper</groupId>
    <artifactId>pagehelper</artifactId>
    <version>5.3.0</version>
</dependency>
```

- **优势**：透明化分页逻辑，简化开发
- 瓶颈：
  - 底层仍用`LIMIT offset, size`（深度分页时性能无改善）
  - 仅优化了DAO层封装，未解决数据库执行计划问题

**方案B: ShardingSphere分库分表**

```sql
/* 按设备ID分片 */
CREATE SHARDING TABLE RULE t_device_log (
  DATANODES("ds_${0..1}.device_log_${0..15}"),
  SHARDING_COLUMN=device_id,
  TYPE(NAME=hash_mod,PROPERTIES("sharding-count"=16))
);
```

- **优势**：将300万数据分散到16个表，每个表仅18万数据
- 致命缺陷：
  - **跨分片排序问题**：`ORDER BY create_time`需归并排序，深度分页反而更慢
  - **架构冲击**：需改造为分布式系统（引入协调节点）
  - **过度设计**：当前数据量300万未达分表临界点（通常>5000万考虑）

**结论**：技术收益与改造成本不匹配

3. **前端交互优化**

**方案A: 无限滚动（Infinite Scroll）**

```javascript
// 前端实现
window.addEventListener('scroll', () => {
  if (window.scrollY + 100 > document.body.scrollHeight) {
    loadNextPage(lastId); // 基于游标加载
  }
});
```

- **优势**：天然适配游标分页，避免跳页需求
- **局限**：无法直接跳转到特定历史页（如查看3天前日志）

**方案B: 分片预加载（Pre-fetching）**

```javascript
// 预加载后续5页
for (let i = 1; i <= 5; i++) {
  prefetchPage(currentPage + i);
}
```

- **优势**：用户翻页时体验流畅
- 瓶颈：
  - 深度分页时预加载代价高（如预加载1000页后的数据）
  - 可能加载大量无用数据（用户可能不继续翻页）

**结论**：仅作为体验优化补充，不解决根本问题

**二、最终选择游标分页的五大理由**

1. **性能指标碾压性优势**
   ​**​测试数据对比​**​（查询第15万页，每页10条）：

   |     **方案**     | 响应时间 | 扫描行数 | 锁持有时间 |
   | :--------------: | :------: | :------: | :--------: |
   | LIMIT 150000,10  |  3200ms  |  150010  |   850ms    |
   | ES scroll search |  1200ms  |    -     |     -      |
   |   **游标分页**   | **35ms** |  **10**  |  **5ms**   |

2. **零新增架构依赖**

   ![](/q_img/​​零新增架构依赖.png)

   - 不引入ES/HBase等新组件，节省2台服务器（年省$5k）
   - 运维复杂度维持不变

3. **业务场景完美契合**

   - **高频场景**：90%操作为「最新日志」和「下一页」（连续浏览）
   - 低频场景：10%的跳页需求可通过替代方案解决：
     - 按时间筛选：`WHERE create_time > '2023-10-01'`
     - 设备ID过滤：`WHERE device_id = 'CAM-001'`

4. **改造成本最低**

   - 后端：仅重写分页查询语句

     ```sql
     /* 优化前 */
     SELECT * FROM logs ORDER BY id LIMIT 150000, 10;
     
     /* 优化后 */
     SELECT * FROM logs WHERE id > 150000 ORDER BY id LIMIT 10;
     ```

   - 前端：将页码参数改为游标参数

     ```diff
     - /api/logs?page=15000&size=10
     + /api/logs?last_id=150000&size=10
     ```

5. **线性扩展能力**

   |   数据规模   | 传统分页TP99 | 游标分页TP99 |
   | :----------: | :----------: | :----------: |
   |     50万     |    800ms     |     15ms     |
   |    300万     |    5000ms    |     18ms     |
   | 1000万(预测) |     超时     |     22ms     |

**三、增强型游标分页实现**

**1. 复合游标支持**

```sql
/* 多列排序场景 */
SELECT * FROM operation_log
WHERE (create_time, id) < ('2023-10-01 12:00:00', 300000)
ORDER BY create_time DESC, id DESC
LIMIT 10;
```

- **创建组合索引**：`(create_time, id)`
- **前端传参**：`?last_time=2023-10-01T12:00:00Z&last_id=300000`

**2. 断页补偿机制**

```java
public PageResponse getLogs(PageRequest request) {
  if (StringUtils.isEmpty(request.getLastId())) {
    // 首页查询：估算游标起点
    long estimatedId = calculateStartId(request.getPage());
    return getLogsByCursor(estimatedId); 
  } else {
    // 游标分页
    return getLogsByCursor(request.getLastId());
  }
}
```

**3. 异构存储分级方案**

图片

![](/q_img/异构存储分级方案.png)

**四、总结：技术选型决策树**

![](/q_img/技术选型决策树.png)

**最终决策依据**：

1. **数据规模**：当前300万+年增长50万 → 5年内不会超过500万
2. **查询模式**：92%操作为顺序浏览（8%跳页可优化）
3. **成本约束**：无预算增加新服务器
4. **时效要求**：故障排查需实时查询最新日志

游标分页以**最小改动解决了核心痛点**（深度分页全表扫描），同时为未来演进预留空间（ES用于历史分析）。